{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Intestinal Validator - Model Training\n",
    "\n",
    "This notebook trains a MobileNetV3 model for photo validation.\n",
    "\n",
    "**Steps:**\n",
    "1. Download training data from Supabase\n",
    "2. Train MobileNetV3 with transfer learning\n",
    "3. Export to TensorFlow.js format\n",
    "4. Download and deploy to web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q tensorflow tensorflowjs supabase Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflowjs as tfjs\n",
    "from supabase import create_client, Client\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¥ Download Training Data from Supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supabase credentials (use your own)\n",
    "SUPABASE_URL = \"your_supabase_url\"\n",
    "SUPABASE_KEY = \"your_supabase_service_role_key\"\n",
    "\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('data/train/valid', exist_ok=True)\n",
    "os.makedirs('data/train/invalid', exist_ok=True)\n",
    "\n",
    "# Download photos\n",
    "response = supabase.table('training_photos').select('*').eq('used_in_training', False).execute()\n",
    "photos = response.data\n",
    "\n",
    "print(f\"Downloading {len(photos)} photos...\")\n",
    "\n",
    "for photo in photos:\n",
    "    try:\n",
    "        file_data = supabase.storage.from_('training-dataset').download(photo['image_url'])\n",
    "        \n",
    "        label = photo['label']\n",
    "        filepath = f\"data/train/{label}/{photo['id']}.jpg\"\n",
    "        \n",
    "        with open(filepath, 'wb') as f:\n",
    "            f.write(file_data)\n",
    "        \n",
    "        if len(photos) < 20 or photos.index(photo) % 10 == 0:\n",
    "            print(f\"Downloaded {photos.index(photo)+1}/{len(photos)}: {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {photo['image_url']}: {e}\")\n",
    "\n",
    "# Count files\n",
    "valid_count = len(os.listdir('data/train/valid'))\n",
    "invalid_count = len(os.listdir('data/train/invalid'))\n",
    "print(f\"\\nâœ… Dataset ready: {valid_count} valid, {invalid_count} invalid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "base_model = MobileNetV3Small(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Freeze base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom head\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Training generator\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Validation generator\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {train_generator.n}\")\n",
    "print(f\"Validation samples: {val_generator.n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nâœ… Training completed!\")\n",
    "print(f\"Final train accuracy: {history.history['accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"Final val accuracy: {history.history['val_accuracy'][-1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Keras model\n",
    "model.save('model.h5')\n",
    "print(\"âœ… Keras model saved\")\n",
    "\n",
    "# Export to TensorFlow.js\n",
    "tfjs.converters.save_keras_model(model, 'tfjs_model')\n",
    "print(\"âœ… TensorFlow.js model exported\")\n",
    "\n",
    "# Download files\n",
    "from google.colab import files\n",
    "\n",
    "print(\"\\nðŸ“¥ Downloading model files...\")\n",
    "files.download('tfjs_model/model.json')\n",
    "files.download('tfjs_model/group1-shard1of1.bin')\n",
    "\n",
    "print(\"\\nâœ… Done! Upload these files to your /public/model/ directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
